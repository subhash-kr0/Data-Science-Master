{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Assignment pdf link](30%20Mar_AssQ.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 1</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 : What is Elastic Net Regression and how does it differ from other regression techniques?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression is a linear regression model that combines the penalties of two different regularization methods, L1 and L2.\n",
    "\n",
    "### L1 regularization, also known as Lasso regularization, adds a penalty term to the objective function that encourages sparse solutions by forcing some of the coefficients to be exactly zero. This makes it useful for feature selection and can help avoid overfitting by reducing the number of variables in the model.\n",
    "\n",
    "### L2 regularization, also known as Ridge regularization, adds a penalty term that shrinks the coefficients towards zero, but does not force them to be exactly zero. This can help reduce the effect of multicollinearity in the data and can also help prevent overfitting.\n",
    "\n",
    "### Elastic Net Regression combines these two methods by adding a penalty term that is a linear combination of the L1 and L2 penalties. The amount of regularization applied by each penalty term is controlled by a tuning parameter that can be adjusted to optimize performance.\n",
    "\n",
    "### Compared to other regression techniques, Elastic Net Regression has the advantage of being able to handle high-dimensional data with correlated predictors. It can also perform both feature selection and coefficient shrinkage simultaneously. However, it may not perform as well as other methods in certain situations, such as when the number of predictors is much larger than the sample size or when there are strong nonlinear relationships between the predictors and the response variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equation for Ridge Regression (L2 Penalty):\n",
    "$ \n",
    "\\mathcal{L}_{\\text{ridge}}(\\mathbf{w}) = \\sum_{i=1}^{n} (y_i - \\mathbf{w}^T\\mathbf{x}_i)^2 + \\lambda 2\\sum_{j=1}^{p} w_j^2\n",
    "$\n",
    "\n",
    "### Equation for Lasso Regression (L1 Penalty) :\n",
    "$\n",
    "\\mathcal{L}_{\\text{lasso}}(\\mathbf{w}) = \\sum_{i=1}^{n} (y_i - \\mathbf{w}^T\\mathbf{x}_i)^2 + \\lambda 1\\sum_{j=1}^{p} |w_j|\n",
    "$\n",
    "\n",
    "### Equation for Elastic Net Regression :\n",
    "$\n",
    "\\mathcal{L}_{\\text{elastic net}}(\\mathbf{w}) = \\sum{i=1}^{n} (y_i - \\mathbf{w}^T\\mathbf{x}i)^2 + \\lambda 1\\sum{j=1}^{p} |\\omega_j| + \\lambda 2\\sum_{j=1}^{p} w_j^2\n",
    "$\n",
    "\n",
    "where :\n",
    "1. $\\mathbf{w}$ represents the vector of regression coefficients\n",
    "2. $\\mathbf{x}_i$ represents the feature vector for the $i$th data point, $y_i$ represents the target value for the $i$th data point. \n",
    "3. $p$ is the number of features\n",
    "4. $\\lambda 1$, $\\lambda 2$ are tuning parameters controlling the strength of the regularization penalty\n",
    "5. $|\\cdot|$ denotes the absolute value function.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 2</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 : How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the optimal values of the regularization parameters for Elastic Net Regression typically involves a process called hyperparameter tuning. The goal is to find the values of $\\lambda_1$ and $\\lambda_2$ that result in the best model performance on a held-out validation set.\n",
    "\n",
    "### Here are the steps for hyperparameter tuning in Elastic Net Regression:\n",
    "\n",
    "1. Split the data into training and validation sets.\n",
    "\n",
    "2. Define a range of values for $\\lambda_1$ and $\\lambda_2$ to try. This range can be chosen based on prior knowledge, or through experimentation. For example, you can try a grid of values or use a randomized search approach.\n",
    "\n",
    "3. Train the Elastic Net model on the training set for each combination of $\\lambda_1$ and $\\lambda_2$ in the range of values defined in step 2.\n",
    "\n",
    "4. Evaluate the model performance on the validation set for each combination of $\\lambda_1$ and $\\lambda_2$.\n",
    "\n",
    "5. Select the values of $\\lambda_1$ and $\\lambda_2$ that result in the best model performance on the validation set.\n",
    "\n",
    "6. There are several metrics you can use to evaluate model performance, such as mean squared error (MSE), mean absolute error (MAE), or R-squared. You can choose the metric that is most appropriate for your problem.\n",
    "\n",
    "### It's important to note that hyperparameter tuning can be computationally expensive, especially if you have a large dataset or a large range of hyperparameter values to try. In some cases, it may be necessary to use techniques like cross-validation or Bayesian optimization to make the tuning process more efficient.\n",
    "\n",
    "### Below is python code for Hyperparameter tuning of Elastic Net :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha:  0.1\n",
      "Best l1_ratio:  0.9\n",
      "Testing MAE: 19.41\n",
      "Testing MSE: 594.31\n",
      "Testing RMSE : 24.38\n",
      "Testing R2 : 0.9649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=25, random_state=42)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define range of alpha and l1_ratio values to try\n",
    "alphas = [0.1, 1.0, 10.0]\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "\n",
    "# Create ElasticNetCV model\n",
    "model = ElasticNetCV(l1_ratio=l1_ratios, alphas=alphas, cv=5)\n",
    "\n",
    "# Train model on training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model on test set\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test,y_test_pred)\n",
    "r2 = r2_score(y_test,y_test_pred)\n",
    "\n",
    "# Print Evaluated Results\n",
    "print(\"Best alpha: \", model.alpha_)\n",
    "print(\"Best l1_ratio: \", model.l1_ratio_)\n",
    "print(f\"Testing MAE: {mae:.2f}\")\n",
    "print(f\"Testing MSE: {mse:.2f}\")\n",
    "print(f\"Testing RMSE : {mse**0.5:.2f}\")\n",
    "print(f\"Testing R2 : {r2:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 3</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : What are the advantages and disadvantages of Elastic Net Regression?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some advantages and disadvantages of Elastic Net Regression:\n",
    "\n",
    "### Advantages:\n",
    "\n",
    "* Elastic Net Regression can handle high-dimensional datasets with many features, as it can perform feature selection and shrinkage simultaneously.\n",
    "* It can handle correlated features well, as it uses a combination of L1 and L2 penalties to balance between sparse and dense solutions.\n",
    "* It allows for a trade-off between bias and variance, as the regularization parameters can be tuned to adjust the degree of shrinkage.\n",
    "* It can be used for both regression and classification problems.\n",
    "\n",
    "### Disadvantages:\n",
    "\n",
    "* Elastic Net Regression can be computationally expensive, especially when dealing with a large number of features or a large dataset.\n",
    "The optimal values for the regularization parameters must be determined through hyperparameter tuning, which can also be computationally expensive.\n",
    "* Elastic Net Regression assumes that the relationship between the features and the target variable is linear. If the relationship is nonlinear, other methods such as decision trees or neural networks may be more appropriate.\n",
    "* It may not perform well if the dataset has a low number of samples compared to the number of features, as this can result in an overfitting of the model.\n",
    "\n",
    "### Overall, Elastic Net Regression can be a useful tool for handling high-dimensional datasets with correlated features, but it may not be the best option for all problems. It's important to carefully consider the advantages and disadvantages before deciding whether to use Elastic Net Regression for a particular task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 4</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : What are some common use cases for Elastic Net Regression?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some common use cases for Elastic Net Regression:\n",
    "\n",
    "1. Gene expression analysis: Elastic Net Regression can be used to analyze gene expression data, where the number of features (genes) is typically much larger than the number of samples. By identifying the most important genes that are associated with a particular disease or condition, researchers can gain insights into the underlying biological mechanisms.\n",
    "\n",
    "2. Financial forecasting: Elastic Net Regression can be used to predict financial variables such as stock prices, exchange rates, and commodity prices. By incorporating multiple features such as historical prices, economic indicators, and news sentiment, the model can capture complex relationships and improve the accuracy of the predictions.\n",
    "\n",
    "3. Marketing analytics: Elastic Net Regression can be used to analyze customer behavior and preferences, and to predict the effectiveness of marketing campaigns. By identifying the most important factors that influence customer decisions, marketers can develop targeted strategies to improve customer engagement and loyalty.\n",
    "\n",
    "4. Image processing: Elastic Net Regression can be used for feature extraction and image denoising. By identifying the most important features that contribute to image classification or reconstruction, the model can improve the accuracy and quality of the results.\n",
    "\n",
    "5. Environmental science: Elastic Net Regression can be used to analyze environmental data such as air and water quality, climate variables, and soil properties. By identifying the most important variables that are associated with environmental degradation or pollution, researchers can develop strategies to mitigate the impacts and protect human health.\n",
    "\n",
    "### Overall, Elastic Net Regression can be used in a wide range of applications where there are high-dimensional datasets with correlated features. By incorporating both L1 and L2 penalties, Elastic Net Regression can balance between sparse and dense solutions, and provide a powerful tool for feature selection and regularization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 5</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 : How do you interpret the coefficients in Elastic Net Regression?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the coefficients in Elastic Net Regression can be slightly more complex than in linear regression due to the presence of the regularization terms. Here are some general guidelines:\n",
    "\n",
    "1. Sign of the coefficient: The sign of the coefficient indicates whether the feature has a positive or negative effect on the target variable. For example, if the coefficient for a feature is positive, then an increase in the value of that feature will lead to an increase in the target variable.\n",
    "\n",
    "2. Magnitude of the coefficient: The magnitude of the coefficient indicates the strength of the relationship between the feature and the target variable. A larger magnitude indicates a stronger relationship. However, it's important to keep in mind that the magnitude of the coefficient can be influenced by the scale of the feature and the target variable.\n",
    "\n",
    "3. Regularization term: The regularization terms in Elastic Net Regression can shrink the magnitude of the coefficients towards zero, which can result in sparser solutions. Therefore, it's important to consider the regularization parameters when interpreting the coefficients. A larger value of the regularization parameter can result in more coefficients being shrunk towards zero, which can lead to a simpler model with fewer features.\n",
    "\n",
    "4. Coefficient stability: The stability of the coefficients across different datasets or subsets of the same dataset can provide information about the robustness of the model. If the coefficients are consistent across different datasets or subsets, then the model is more likely to generalize well to new data.\n",
    "\n",
    "### In summary, interpreting the coefficients in Elastic Net Regression requires considering the sign, magnitude, and stability of the coefficients, as well as the influence of the regularization terms. It's important to interpret the coefficients in the context of the specific application and to validate the model's performance on new data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 6</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 : How do you handle missing values when using Elastic Net Regression?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values is an important preprocessing step when using Elastic Net Regression. Here are some common strategies for handling missing values:\n",
    "\n",
    "1. Remove samples with missing values: One simple approach is to remove samples with missing values from the dataset. However, this approach can lead to loss of information and reduced sample size.\n",
    "\n",
    "2. Impute missing values: Imputation is the process of replacing missing values with estimated values. There are several imputation methods available, such as mean imputation, median imputation, and regression imputation. Mean or median imputation can be used for continuous variables, while regression imputation can be used to predict missing values based on other variables.\n",
    "\n",
    "3. Use a missing value indicator: Another approach is to create a binary indicator variable that indicates whether a particular feature has a missing value or not. This approach allows the model to distinguish between missing and non-missing values and can help preserve information.\n",
    "\n",
    "### When using Elastic Net Regression, it's important to apply the same preprocessing steps to both the training and test datasets. Imputation and missing value indicators should be applied to both datasets to ensure that the model is consistent and generalizable.\n",
    "\n",
    "### It's also important to keep in mind that imputation can introduce bias and reduce the variability in the data. Therefore, it's important to validate the performance of the model with and without imputation, and to choose an appropriate imputation method based on the characteristics of the dataset and the specific application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha:  0.0015970391288520694\n",
      "Best l1_ratio:  0.5\n",
      "Testing MAE: 0.53\n",
      "Testing MSE: 0.55\n",
      "Testing RMSE : 0.74\n",
      "Testing R2 : 0.5770\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "X, y = california_housing.data, california_housing.target\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create imputer object for mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit imputer to training data and transform both training and test data\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scaling the dataset \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Create Elastic Net model with cross-validation to choose hyperparameters\n",
    "model = ElasticNetCV(cv=5)\n",
    "\n",
    "# Fit model to training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model on test set\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test,y_test_pred)\n",
    "r2 = r2_score(y_test,y_test_pred)\n",
    "\n",
    "# Print Evaluated Results\n",
    "print(\"Best alpha: \", model.alpha_)\n",
    "print(\"Best l1_ratio: \", model.l1_ratio_)\n",
    "print(f\"Testing MAE: {mae:.2f}\")\n",
    "print(f\"Testing MSE: {mse:.2f}\")\n",
    "print(f\"Testing RMSE : {mse**0.5:.2f}\")\n",
    "print(f\"Testing R2 : {r2:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 7</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 : How do you use Elastic Net Regression for feature selection?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression can be used for feature selection by setting the L1 ratio parameter to a value between 0 and 1. When the L1 ratio is 1, Elastic Net Regression becomes equivalent to Lasso Regression, which is known for its feature selection properties. The L1 penalty in Lasso Regression forces some of the coefficients to become exactly zero, effectively selecting only the most important features for the model.\n",
    "\n",
    "### To use Elastic Net Regression for feature selection, you can set the L1 ratio to a value close to 1 (e.g., 0.9) and use cross-validation to select the best value for the regularization parameter alpha. The resulting model will have some coefficients that are exactly zero, indicating that those features were not selected by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.5148375114202305\n",
      "Selected features: [('MedInc', 0.7124071084662037), ('HouseAge', 0.13719421046603505), ('Latitude', -0.17588665188849656), ('Longitude', -0.1333428456446479)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Elastic Net model with cross-validation to choose hyperparameters\n",
    "model = ElasticNetCV(l1_ratio=0.5, alphas=[0.1, 0.5, 1.0],cv=5)\n",
    "\n",
    "# Fit model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model on testing data\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"R^2 score:\", score)\n",
    "\n",
    "# Get coefficients and feature names\n",
    "coef = model.coef_\n",
    "feature_names = california.feature_names\n",
    "\n",
    "# Print selected features and their coefficients\n",
    "selected_features = []\n",
    "for i in range(len(feature_names)):\n",
    "    if coef[i] != 0:\n",
    "        selected_features.append((feature_names[i], coef[i]))\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 8</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 : How do you pickle and unpickle a trained Elastic Net Regression model in Python?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle is a Python module that can be used to serialize and save Python objects to disk. This makes it a useful tool for saving trained machine learning models, including Elastic Net Regression models. Here's an example of how to pickle and unpickle an Elastic Net Regression model in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  33.76505377   67.70054112   -5.23557654 -274.54102976   36.68328734]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a random regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise =25, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an Elastic Net model with cross-validation\n",
    "enet = ElasticNetCV(cv=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "enet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Pickle the trained model to a file\n",
    "with open('enet_model.pkl', 'wb') as f:\n",
    "    pickle.dump(enet, f)\n",
    "\n",
    "# Unpickle the model from the file\n",
    "with open('enet_model.pkl', 'rb') as f:\n",
    "    enet_loaded = pickle.load(f)\n",
    "\n",
    "# Use the unpickled model to make predictions on the testing data\n",
    "y_pred = enet_loaded.predict(X_test_scaled)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this code, we first train an Elastic Net Regression model on the Boston Housing dataset and then pickle it to a file using the pickle.dump() method. We then unpickle the model from the file using the pickle.load() method and use it to make predictions on a new data point. Note that we also need to load the StandardScaler object used to scale the data in order to scale the new data point before making predictions.\n",
    "\n",
    "### Pickle can be a convenient way to save trained machine learning models, but it's important to be aware of its limitations and potential security risks. In particular, unpickling untrusted data can potentially execute arbitrary code, so it's important to only unpickle data from trusted sources."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "\n",
    "# <p style=\"padding:10px;background-color:#87CEEB ;margin:10;color:#000000;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 10px 10px ;overflow:hidden;font-weight:50\">Question 9</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 : What is the purpose of pickling a model in machine learning?\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The purpose of pickling a model in machine learning is to save the trained model to a file so that it can be used later without having to retrain the model. Pickling is a way to serialize the object and store it in a file, which can then be loaded later when needed. This is useful when the model takes a long time to train, or when you want to use the same model to make predictions on new data without having to train it from scratch every time.\n",
    "\n",
    "### In addition to saving time, pickling can also help ensure consistency between different environments. For example, if you train a model on one machine and then transfer it to another machine for use in a production environment, pickling allows you to maintain the same trained model, rather than retraining the model on the new machine, which may produce slightly different results due to differences in hardware or software configurations.\n",
    "\n",
    "### Overall, pickling is a convenient and efficient way to save trained machine learning models for later use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pickling](load-save-model.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
